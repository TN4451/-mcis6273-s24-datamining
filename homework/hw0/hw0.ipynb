{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935555f7-c4dd-43df-a9b5-84a678f5adda",
   "metadata": {},
   "source": [
    "## HW0 ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8a97c-753b-40ad-95f3-96b5187a8ce1",
   "metadata": {},
   "source": [
    "### OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3068c23-7a1a-425e-812d-50520d1bd241",
   "metadata": {},
   "source": [
    "- Familiarize yourself with Github and basic git\n",
    "- Familiarize yourself with the JupyterLab environment, Markdown, and Python\n",
    "- Explore the JupyterHub Linux console integrating what you learned in the prior parts of this homework\n",
    "- Perform basic data engineering in Python using NOAA weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72810c2f-c60b-46dd-a188-dcceb5de20c1",
   "metadata": {},
   "source": [
    "### Obtaining API Key "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7a881-564b-41cd-84a7-50280ac8164f",
   "metadata": {},
   "source": [
    "1. Access URL: https://www.ncdc.noaa.gov/cdo-web/token\n",
    "2. Enter your Email Address in the above URL.\n",
    "3. Access Token is delivered to the Email..W "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ef95e-a331-44d5-a85b-11a15230a12f",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9056eba7-3b53-4f80-b687-2736b8a28562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json \n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963f570-8d9d-4cce-b40b-79f6ad5e602c",
   "metadata": {},
   "source": [
    "### ยง Task: Use Python to make HTTP/API calls to NOAA services and obtain data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a6969-aba6-4fb0-b686-e0f2189334f4",
   "metadata": {},
   "source": [
    "#### Creation of JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac15e72-75ff-4048-9313-12de662a8eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieval and storage complete.\n"
     ]
    }
   ],
   "source": [
    "## Function to fetch data from NOAA in a given range\n",
    "def get_noaa_data_range(start_date, end_date, api_token):\n",
    "    data_url = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data'\n",
    "    params = {\n",
    "        'datasetid' : 'GHCND',\n",
    "        'locationid' : 'ZIP:80249',\n",
    "        'units' : 'standard',\n",
    "        'startdate' : start_date,\n",
    "        'enddate' : end_date,\n",
    "        'limit' : 1000\n",
    "    }\n",
    "    headers = {'token': api_token}\n",
    "    \n",
    "    response = requests.get(data_url, headers = headers, params = params)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Return the JSON response\n",
    "        return response.json()\n",
    "    else:\n",
    "        # If request was not successful, print error message\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "# Create a directory to store the data\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "api_token = 'CTXujlIECPVrbVTpfUkRWzUqSfEuBvKW'\n",
    "\n",
    "## Looping through the year 2008-2022 and between dates 12/15 to 1/21\n",
    "for year in range(2008, 2023):\n",
    "    start_date = f'{year}-12-15'\n",
    "    end_date = f'{year+1}-01-21'\n",
    "    data = get_noaa_data_range(start_date, end_date, api_token)\n",
    "    \n",
    "    with open(f'data/winter_{year}-{year+1}.json', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "print(\"Data retrieval and storage complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ad875-47e3-4e62-b63b-d5ccdd4d8e0c",
   "metadata": {},
   "source": [
    "### ยง Task: Extract, transform, and export JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9efb677-88ec-491a-9e0c-f5bac8764826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been successfully generated and saved to path data/all_data_max_min_avg.csv\n"
     ]
    }
   ],
   "source": [
    "## Folder containing data \n",
    "data_folder = 'data/'\n",
    "\n",
    "## Initialize data frame to store data \n",
    "transform_json_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all JSON files in the data folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        # Read the JSON file into a DataFrame\n",
    "        with open(os.path.join(data_folder, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data['results'])\n",
    "\n",
    "            # Convert the 'date' column to datetime format\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            # Extract only the date part (YYYY-MM-DD) from the datetime column\n",
    "            df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Extracting the values of TMAX and TMIN and renaming the columns respectively\n",
    "            df_tmax = df[df['datatype'] == 'TMAX'][['date', 'value']]\n",
    "            df_tmin = df[df['datatype'] == 'TMIN'][['date', 'value']]\n",
    "            df_tmax.rename(columns = {'value' : 'TMAX'}, inplace = True)\n",
    "            df_tmin.rename(columns = {'value' : 'TMIN'}, inplace = True)\n",
    "            \n",
    "            # Merge df_tmax and df_tmin on the 'date' column\n",
    "            df_max_min = pd.merge(df_tmax, df_tmin, on = 'date')\n",
    "\n",
    "            # Calculate TAVG \n",
    "            df_max_min['TAVG'] = (df_max_min['TMAX'] + df_max_min['TMIN']) / 2\n",
    "            \n",
    "            # Adding processed data to weather_data\n",
    "            transform_json_data = pd.concat([transform_json_data, df_max_min])\n",
    "\n",
    "# Sort by date\n",
    "transform_json_data.sort_index(inplace=True)\n",
    "\n",
    "# Saving to CSV \n",
    "csv_file_path = os.path.join(data_folder, 'all_data_max_min_avg.csv')\n",
    "transform_json_data.to_csv(csv_file_path)\n",
    "\n",
    "print(f'The file has been successfully generated and saved to path {csv_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b763a-b861-4891-947b-3ca2a58b3fd0",
   "metadata": {},
   "source": [
    "### ยง Task: Filter, transform and export CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37a61172-de65-4b72-868f-0df75db5fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12-15': 54.0, '12-16': 52.0, '12-17': 44.0, '12-18': 45.0, '12-19': 61.0, '12-20': 60.0, '12-21': 63.0, '12-22': 64.0, '12-23': 62.0, '12-24': 52.0, '12-25': 55.0, '12-26': 53.0, '12-27': 48.0, '12-28': 33.0, '12-29': 33.0, '12-30': 49.0, '12-31': 39.0, '01-01': 8.0, '01-02': 40.0, '01-03': 51.0, '01-04': 47.0, '01-05': 34.0, '01-06': 27.0, '01-07': 57.0, '01-08': 43.0, '01-09': 34.0, '01-10': 56.0, '01-11': 57.0, '01-12': 58.0, '01-13': 62.0, '01-14': 45.0, '01-15': 50.0, '01-16': 57.0, '01-17': 62.0, '01-18': 58.0, '01-19': 31.0, '01-20': 39.0, '01-21': 36.0}\n",
      "{'12-15': 54.0, '12-16': 52.0, '12-17': 44.0, '12-18': 45.0, '12-19': 61.0, '12-20': 60.0, '12-21': 63.0, '12-22': 64.0, '12-23': 62.0, '12-24': 52.0, '12-25': 55.0, '12-26': 53.0, '12-27': 48.0, '12-28': 33.0, '12-29': 33.0, '12-30': 49.0, '12-31': 39.0, '01-01': 8.0, '01-02': 40.0, '01-03': 51.0, '01-04': 47.0, '01-05': 34.0, '01-06': 27.0, '01-07': 57.0, '01-08': 43.0, '01-09': 34.0, '01-10': 56.0, '01-11': 57.0, '01-12': 58.0, '01-13': 62.0, '01-14': 45.0, '01-15': 50.0, '01-16': 57.0, '01-17': 62.0, '01-18': 58.0, '01-19': 31.0, '01-20': 39.0, '01-21': 36.0}\n"
     ]
    }
   ],
   "source": [
    "## Folder containing data \n",
    "data_folder = 'data/'\n",
    "\n",
    "## Initialize data frame to store data \n",
    "compiled_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all JSON files in the data folder\n",
    "for year in range (2008, 2023):\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith('.json'):\n",
    "        # Read the JSON file into a DataFrame\n",
    "            with open(os.path.join(data_folder, filename), 'r') as f:\n",
    "                data = json.load(f)['results']\n",
    "                tmax_values = {}\n",
    "                tmin_values = {}\n",
    "                for record in data:\n",
    "                    date_str = record['date'][5:10]\n",
    "                    if record['datatype'] == 'TMAX':\n",
    "                        tmax_values[date_str] = record['value']\n",
    "                    elif record['datatype'] == 'TMIN':\n",
    "                        tmin_values[date_str] = record['value']\n",
    "\n",
    "                for date_str in tmax_values:\n",
    "                    if date_str in tmin_values:\n",
    "                        tavg = (tmax_values[date_str] + tmin_values[date_str]) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245019bc-e1bb-4fec-9d22-49bf6be611eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sau24s]",
   "language": "python",
   "name": "conda-env-sau24s-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
